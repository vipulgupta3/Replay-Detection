{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "replaydetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN24Ke+qkoJwZjcDuseQPhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipulgupta3/Replay-Detection/blob/master/replaydetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KObozPlWQYsT",
        "colab_type": "code",
        "outputId": "7e3809fc-a9fe-4bd3-9fad-7a86e9d05365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import cv2\n",
        "import pafy\n",
        "url = 'https://www.youtube.com/watch?v=GrvjIhG1oZc&t=1s'\n",
        "video = pafy.new(url)\n",
        "best=video.getbest()\n",
        "best.url\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.0\n",
            "720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT0K1B4xRdTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap=cv2.VideoCapture(best.url)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(fps)\n",
        "cap.isOpened()\n",
        "ret,frame=cap.read()\n",
        "print(len(frame))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zmtNQi0ReLJ",
        "colab_type": "code",
        "outputId": "142340ff-bf7a-40c6-989f-a780de2e0612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6j1vouheOWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path=\"/content/drive/My Drive/task\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZd7KVEfCDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "labels=os.listdir(train_path)\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Hyx0mwOuqZ",
        "colab_type": "code",
        "outputId": "10425f3d-92fc-4694-cbf2-85cd8e3a77bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "source": [
        "image=cv2.imread(train_path+'/'+label+'/'+img)\n",
        "print(image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 67  57  69]\n",
            "  [ 64  55  65]\n",
            "  [ 68  57  65]\n",
            "  ...\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]]\n",
            "\n",
            " [[ 85  72  88]\n",
            "  [ 64  51  65]\n",
            "  [ 55  43  55]\n",
            "  ...\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]]\n",
            "\n",
            " [[133 114 139]\n",
            "  [ 95  77 100]\n",
            "  [ 73  56  77]\n",
            "  ...\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]\n",
            "  [ 38  27  23]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 34  36  37]\n",
            "  [ 34  36  37]\n",
            "  [ 34  36  37]\n",
            "  ...\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]]\n",
            "\n",
            " [[ 34  36  37]\n",
            "  [ 33  35  36]\n",
            "  [ 35  34  36]\n",
            "  ...\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]]\n",
            "\n",
            " [[ 34  36  37]\n",
            "  [ 34  36  37]\n",
            "  [ 36  35  37]\n",
            "  ...\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]\n",
            "  [ 37  36  38]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK-BrxIefO6v",
        "colab_type": "code",
        "outputId": "796c4abb-42f0-4fd1-839f-db7edfeb8115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "all_labels=[]\n",
        "all_pictures=[]\n",
        "dim=(50,50)\n",
        "for label in labels:\n",
        "  images=[f for f in os.listdir(train_path+'/'+label)]\n",
        "  for img in images:\n",
        "    pic=cv2.imread(train_path+'/'+label+'/'+img)\n",
        "    pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
        "    image=cv2.resize(pic,dim)\n",
        "    image=image[0:10,5:15]\n",
        "    all_pictures.append((np.array(image)))\n",
        "    print(np.array(image))\n",
        "    all_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[15 15 15 15 15 15 15 15 15 15]\n",
            " [15 15 15 15 15 15 15 15 15 15]\n",
            " [15 15 15 15 15 15 15 15 15 15]\n",
            " [15 16 15 16 15 15 15 15 15 15]\n",
            " [15 16 15 15 15 15 15 15 15 15]\n",
            " [16 16 16 16 15 15 15 15 15 15]\n",
            " [16 15 16 16 15 15 15 15 15 15]\n",
            " [16 15 16 16 15 15 15 16 15 16]\n",
            " [16 16 15 15 15 15 15 15 16 16]\n",
            " [16 15 15 15 15 16 15 15 17 16]]\n",
            "[[ 11  50  68  59  16 135  86 112  57  62]\n",
            " [ 30  53  50  88  44  64  51  60  65  72]\n",
            " [ 23  77  38  74 116  69  48  68  61  58]\n",
            " [ 28  49  85  53  27  69  55  47  59  64]\n",
            " [ 40  14  97  78  54  37  38  32  55  56]\n",
            " [ 44  18  68  59  70  25  70  53  59  60]\n",
            " [ 51  29  61  93  42  58  87  82  60  59]\n",
            " [ 57  79  31  29  31  66  37  59  65  65]\n",
            " [ 84  83  49  56  24  80  37  28  68  71]\n",
            " [ 41  18  56 107  40  58  66  28  71  73]]\n",
            "[[ 63  98  78  58  55  81  86  86  70  83]\n",
            " [ 81 119  48  94  63  85  90  86  93  92]\n",
            " [ 91  54  91  92 107  77  92  92  88  77]\n",
            " [ 57  39 148  25 103  57 116  98  97  89]\n",
            " [ 40  37  36  37  38  67  36  38  37  40]\n",
            " [107 108 105 105 102 106 102 251 101 104]\n",
            " [251 233 179 173 149 221  98 212 238 184]\n",
            " [115 127 138 149 149 144 141 142 145 145]\n",
            " [135 137 137 134 127 128 128 129 129 130]\n",
            " [143 144 141 133 131 131 132 132 132 131]]\n",
            "[[ 61  62  61  63  64  65  66  64  65  60]\n",
            " [ 59  60  49  63 116  59  63  64  50  70]\n",
            " [ 60  41  61  61  63  90  61  65  59  60]\n",
            " [ 53  56  58  60  57  57  58  37  58  59]\n",
            " [ 56  59  54  55  57  55  50  57  53  55]\n",
            " [ 62 233  52  63 129  54  50  69  57  53]\n",
            " [ 60  59  60  62  64  49  52  68  60  54]\n",
            " [ 62  65  61  69  63  53  56  65  61  60]\n",
            " [ 66  68  69  68  67  58  72  69  54  65]\n",
            " [ 39  40  41  40  42  50  43  49  50  57]]\n",
            "[[ 64  66  67 147 113  64 249 249 245 244]\n",
            " [ 64  64  64  62  64  65 248 248 248 245]\n",
            " [ 64  64  64  65  64  66 209 217  72 242]\n",
            " [113 110 107 106  92 110 101  96  84  71]\n",
            " [ 91  92  96  84  84  85  84  80  77  75]\n",
            " [ 99 106 162 150 153 123 153 145 103  93]\n",
            " [109 107 113 100  87  77  96 109 101 102]\n",
            " [122 120 124 122 121 120 120 121 123 124]\n",
            " [123 126 126 126 126 125 124 124 125 125]\n",
            " [125 126 125 126 126 126 126 126 125 126]]\n",
            "[[ 65  66  54  60  67  55  46  54  53  66]\n",
            " [ 68  64  57  66  73  69  52  51  56  71]\n",
            " [ 67  61  65  70  73  74  63  50  59  52]\n",
            " [ 57  59  68  70  74  75  70  57  10  32]\n",
            " [ 53  57  68  68  74  75  74 197  57  50]\n",
            " [ 52  51  60  58  71  74  74 138  56  46]\n",
            " [ 51  41  38  43  68  74  67 148  52 205]\n",
            " [ 52  36  24  33  64  66  40 157 103 119]\n",
            " [ 57  32  32  37  58  53  38 199 151  31]\n",
            " [ 59  46  56  60  58  58  46 163 151  37]]\n",
            "[[ 18  22  23  25  26  30  33  38  43  49]\n",
            " [ 18  21  23  25  28  30  33  38  44  47]\n",
            " [ 18  21  23  26  26  30  33  37  42  46]\n",
            " [ 18  21  23  25  26  30  32  36  39  45]\n",
            " [113  20  21  25  26  29  31  35  38  43]\n",
            " [114 113 113 108  28  29  31  36  38  43]\n",
            " [ 54  63 115 114 115 115 111  37  37  42]\n",
            " [ 51  51  47  52  64 113 116 118 117 120]\n",
            " [ 43  51  51  51  56  57  60  60  85 120]\n",
            " [ 82  41  51  54  54  56  58  59  63  67]]\n",
            "[[150 148 149 149 149 149 146 145 145 145]\n",
            " [149 149 149 150 149 147 145 145 145 144]\n",
            " [157 155 156 156 157 155 153 152 150 150]\n",
            " [158 158 158 158 157 156 155 153 151 149]\n",
            " [158 157 157 158 157 155 156 152 152 152]\n",
            " [155 156 156 158 158 157 155 155 155 152]\n",
            " [172 153 152 150 156 156 156 155 155 153]\n",
            " [112 149 151 153 153 153 155 156 156 153]\n",
            " [154 160 156 158 158 157 158 159 157 156]\n",
            " [157 157 157 157 157 157 157 157 157 158]]\n",
            "[[150 143 143 143 142 141 141 141 143 143]\n",
            " [144 144 144 144 142 141 138 141 139 143]\n",
            " [145 145 146 146 146 146 145 145 145 145]\n",
            " [158 146 145 145 145 144 146 145 146 144]\n",
            " [149 146 144 145 145 145 144 144 145 145]\n",
            " [163 146 146 146 146 146 148 148 148 149]\n",
            " [151 148 150 149 149 149 148 147 146 149]\n",
            " [148 148 149 150 149 149 149 149 150 150]\n",
            " [151 149 151 152 151 152 152 152 151 150]\n",
            " [150 150 150 151 151 146 147 149 148 147]]\n",
            "[[150 150 148 148 148 148 146 146 147 145]\n",
            " [149 150 150 150 149 151 146 148 148 146]\n",
            " [149 149 149 152 153 152 150 149 151 151]\n",
            " [144 146 144 144 145 145 144 145 142 145]\n",
            " [146 145 144 146 144 144 144 146 140 141]\n",
            " [146 145 146 145 145 146 145 145 144 144]\n",
            " [144 146 145 148 146 145 148 147 149 143]\n",
            " [145 145 144 144 145 145 147 148 146 145]\n",
            " [140 141 141 143 143 145 145 145 145 142]\n",
            " [144 145 143 144 144 145 144 150 149 143]]\n",
            "[[147 147 146 143 143 142 142 142 138 139]\n",
            " [145 145 144 143 142 143 142 143 141 142]\n",
            " [151 150 148 149 146 148 146 145 145 148]\n",
            " [151 151 150 149 151 150 150 147 148 148]\n",
            " [151 152 149 150 151 150 151 150 150 151]\n",
            " [149 148 148 149 148 151 148 152 149 151]\n",
            " [148 146 147 145 146 144 145 143 147 141]\n",
            " [149 148 146 146 146 146 145 145 145 144]\n",
            " [146 145 145 146 146 145 147 147 146 149]\n",
            " [148 144 144 145 145 145 143 144 145 146]]\n",
            "[[12 11 30 44 52 54 51 38 16 25]\n",
            " [24 15 25 39 50 52 55 40 18 25]\n",
            " [35 29 33 44 51 54 56 40 17 24]\n",
            " [46 37 38 45 51 53 52 36 13 20]\n",
            " [55 47 45 50 52 53 52 33 11 20]\n",
            " [59 54 53 52 52 53 50 31 12 20]\n",
            " [63 58 51 53 53 53 52 35 12 23]\n",
            " [71 49 53 54 54 57 53 35 11 27]\n",
            " [78 46 48 53 53 56 55 35  9 27]\n",
            " [80 42 45 52 53 61 58 38 11 32]]\n",
            "[[56 56 59 58 60 60 60 55 54 59]\n",
            " [61 59 54 52 60 62 62 61 60 58]\n",
            " [62 61 55 52 60 62 64 64 62 59]\n",
            " [64 64 61 59 63 64 65 64 64 62]\n",
            " [67 67 64 61 62 65 66 67 67 65]\n",
            " [68 68 63 56 62 65 67 68 67 66]\n",
            " [68 68 64 47 65 65 67 67 67 67]\n",
            " [68 70 64 45 65 68 68 67 67 67]\n",
            " [70 71 65 47 66 68 70 70 70 67]\n",
            " [71 72 65 52 68 71 71 70 71 66]]\n",
            "[[143 142 141 139 142 145 145 148 150 151]\n",
            " [145 145 144 144 145 144 145 147 149 150]\n",
            " [145 146 146 146 146 146 146 145 148 149]\n",
            " [146 146 145 145 146 146 146 145 147 149]\n",
            " [150 150 149 150 149 149 147 149 147 147]\n",
            " [152 152 151 152 152 152 151 151 151 152]\n",
            " [152 153 151 151 151 152 153 153 154 153]\n",
            " [154 154 153 155 155 155 155 156 155 155]\n",
            " [153 152 153 153 153 153 153 151 155 153]\n",
            " [153 155 153 153 155 153 153 155 155 155]]\n",
            "[[143 143 144 148 149 149 149 149 150 150]\n",
            " [151 146 151 156 153 158 160 160 159 159]\n",
            " [151 150 154 152 155 159 160 159 160 160]\n",
            " [151 153 153 155 156 157 158 157 156 160]\n",
            " [107 125 134 121 110 109 109 114 112 107]\n",
            " [183 167 168 170 171 118  99 102 102  93]\n",
            " [ 89  91  94  93  92 101  98  97 100 101]\n",
            " [152 153 154 157 157 162 158 162 163 160]\n",
            " [153 156 154 156 159 162 162 164 166 163]\n",
            " [153 156 155 156 159 164 163 164 163 165]]\n",
            "[[151 151 151 151 150 150 150 150 150 149]\n",
            " [151 151 153 151 150 150 152 151 149 150]\n",
            " [151 152 151 151 151 150 150 151 150 150]\n",
            " [153 153 153 154 154 156 156 154 154 156]\n",
            " [155 156 156 158 157 157 157 158 158 156]\n",
            " [158 159 159 158 159 159 159 158 158 158]\n",
            " [154 156 155 154 156 157 158 158 158 158]\n",
            " [156 156 156 156 155 155 156 156 156 157]\n",
            " [157 158 157 158 157 155 157 157 151 157]\n",
            " [159 153 158 159 158 156 157 159 160 158]]\n",
            "[[ 19  14  13  16  17  13  12  12  12  13]\n",
            " [ 86 102  97  92  95  77  12  12  12  13]\n",
            " [ 56  46  31  41  44  39  15  13  15  12]\n",
            " [ 54  51  36  49  43 101 101 104 104 106]\n",
            " [ 27  27  29  28  27  41  47  24  39  38]\n",
            " [ 31  37  32  27  25  47  22  18  19  20]\n",
            " [ 40  39  37  28  31  26  30  24  23  21]\n",
            " [ 47  61  56  40  45  37  41  40  36  31]\n",
            " [ 50  22  55  54  49  51  76  64  22  51]\n",
            " [ 27  59  40  51  41  45  38  70  45  41]]\n",
            "[[123 124 122 123 124 124 125 125 125 124]\n",
            " [124 125 123 123 121 125 125 125 126 125]\n",
            " [126 122 126 124 124 128 128 127 128 127]\n",
            " [128 128 126 126 128 125 128 128 130 128]\n",
            " [130 129 133 131 131 131 131 130 130 132]\n",
            " [132 134 135 134 136 135 137 134 134 137]\n",
            " [135 137 136 136 136 137 137 137 138 137]\n",
            " [136 137 137 136 136 137 137 137 138 138]\n",
            " [138 138 138 138 138 139 138 137 138 138]\n",
            " [139 138 139 137 139 139 139 139 138 139]]\n",
            "[[16 15 23 35 31 26 23 19 17 27]\n",
            " [29 28 35 40 32 29 29 31 30 32]\n",
            " [38 37 35 41 37 36 38 40 39 39]\n",
            " [37 33 31 36 32 30 38 39 40 36]\n",
            " [29 21 18 23 20 19 32 38 37 32]\n",
            " [25 18 16 19 17 15 28 33 32 30]\n",
            " [25 18 17 16 16 16 20 22 23 21]\n",
            " [43 37 24 22 32 32 32 32 20 23]\n",
            " [60 56 41 34 49 50 49 50 33 41]\n",
            " [67 65 47 42 61 62 64 61 42 54]]\n",
            "[[33 27 25 20 20 21 21 22 23 48]\n",
            " [31 33 30 25 25 25 25 25 28 53]\n",
            " [47 35 32 31 30 31 29 30 30 51]\n",
            " [43 67 32 34 33 31 31 29 41 58]\n",
            " [20 67 32 33 32 33 32 30 60 17]\n",
            " [24 65 35 37 34 30 25 32 60 11]\n",
            " [74 33 25 31 33 37 34 40 40 23]\n",
            " [60 43 38 39 29 37 39 39 37 62]\n",
            " [72 57 73 43 43 43 45 46 28 69]\n",
            " [93 87 90 93 88 89 86 76 88 82]]\n",
            "[[129 136 135 134 134 135 133 135 135 135]\n",
            " [136 138 142 142 144 141 138 137 137 135]\n",
            " [141 142 142 143 143 143 143 141 141 139]\n",
            " [139 139 141 143 143 144 142 142 141 141]\n",
            " [140 142 142 143 142 143 142 142 142 141]\n",
            " [139 141 141 142 142 143 143 142 142 143]\n",
            " [139 138 141 142 142 143 142 142 142 142]\n",
            " [143 138 142 144 139 141 139 143 142 142]\n",
            " [142 143 142 144 140 143 138 143 143 143]\n",
            " [141 142 143 143 143 143 143 142 140 142]]\n",
            "[[117  77 111  96 135 137 140 124 135  75]\n",
            " [ 52 101 102 116  77  94  56 107  81 119]\n",
            " [131  63 124 205 138 181 110 173 108 132]\n",
            " [ 70  70  68  70  68  70  71 191 243  85]\n",
            " [ 69 217 225 216 163  79  71 172 249 246]\n",
            " [174 210 218 102  93 209 222 103 249 247]\n",
            " [ 73  75  71  71  71  67  69  70 247 245]\n",
            " [ 98  98  98  98 109 109 126 126 107 107]\n",
            " [155 163 185 156 132 165 148 161 172 168]\n",
            " [135 134 134 134 134 132 131 135 132 129]]\n",
            "[[149 145 116  73 126  95  99  95 165  99]\n",
            " [ 72 178  84  80  68  38  59  64 113 110]\n",
            " [ 58  59  65  60  60  70 169 200  31  87]\n",
            " [118  59 170 176  62  60 168 181  39  33]\n",
            " [174  59  70  58  60  58  50  46  27  51]\n",
            " [ 63  59  52  48  49  75  67 106  81  87]\n",
            " [116 117 115 116 117 115 123 114  75 119]\n",
            " [ 98 136 119  63  89 127 127 125 125 124]\n",
            " [129 130 130 130 130 128 129 128 128 128]\n",
            " [127 127 127 125 125 125 125 125 127 130]]\n",
            "[[46 59 63 63 61 63 59 56 58 63]\n",
            " [43 59 61 61 61 60 61 56 60 61]\n",
            " [48 64 67 66 66 64 64 60 64 67]\n",
            " [52 67 69 67 66 66 67 64 64 70]\n",
            " [52 65 67 66 65 64 67 65 62 67]\n",
            " [50 60 65 67 66 65 65 61 57 65]\n",
            " [49 59 67 71 72 70 70 65 54 68]\n",
            " [60 55 68 70 70 70 71 69 48 67]\n",
            " [57 51 67 67 71 71 70 69 45 64]\n",
            " [64 50 75 75 72 72 72 73 44 71]]\n",
            "[[ 80  62  39  58  64  64  70  70  70  74]\n",
            " [ 87  67  43  55  61  63  72  72  73  74]\n",
            " [ 95  71  51  57  63  61  72  73  73  75]\n",
            " [104  76  53  55  64  65  73  74  73  74]\n",
            " [107  80  58  57  64  67  73  75  75  75]\n",
            " [108  80  59  63  70  72  76  78  76  76]\n",
            " [111  78  68  74  74  73  75  78  77  76]\n",
            " [113  73  77  88  83  75  78  79  78  78]\n",
            " [108  74  83  96  87  76  77  78  77  78]\n",
            " [100  79  96 104  91  75  75  75  76  75]]\n",
            "[[ 39  44  44  29  50  52  45  30  47  46]\n",
            " [ 47  53  41  33  61  59  35  31  66  63]\n",
            " [ 41  48  45  29  60  57  33  37  47  47]\n",
            " [ 42  50  43  44  55  51  36  62  66  66]\n",
            " [ 57  62  38  59  58  50  31  57  60  54]\n",
            " [ 43  51  49  47  45  52  38  53  54  75]\n",
            " [ 61  46  38  64  52  34  69  51  53  56]\n",
            " [136 172 181 223 196 230  58 114 113 112]\n",
            " [ 58  49  46  58  47  45  55  65  64  67]\n",
            " [ 60  59  59  64  46  44  57  57  60  71]]\n",
            "[[114 113 113 113 111 110 110 109 109 109]\n",
            " [110 110 110 110 111 110 108 109 111 137]\n",
            " [110 109 108 108 150 107 168  96  99 109]\n",
            " [113 138 176  99  96 111 113 113 111 109]\n",
            " [ 57 115 115 115 115 116 115 115 116 115]\n",
            " [117 118 118 120 121 119 121 121 121 121]\n",
            " [121 122 121 121 122 122 123 122 122 122]\n",
            " [122 121 121 121 121 121 120 121 121 121]\n",
            " [118 118 118 120 120 120 120 120 121 122]\n",
            " [116 116 116 118 118 118 118 119 120 120]]\n",
            "[[ 73  71  80  89  56  85  87  74  93  85]\n",
            " [ 70  80  91  76  84  90  57  87 101  63]\n",
            " [ 75  84  83  91  93  89  97  96  90  71]\n",
            " [118  90  93  64  93  93  74  92 100  95]\n",
            " [ 37  91  91 101  90  95  92 108 108  99]\n",
            " [103 106 102  86 147 101  55  95  98 107]\n",
            " [ 63  64  62  61  32  61  63  64  64  60]\n",
            " [ 67  62  59  63  45  60  62  59  61  61]\n",
            " [205 230  89 102 102 197 248  89 141 100]\n",
            " [ 96 129 167 101 102 102 203 107  93 100]]\n",
            "[[130 130 129 120 118 118 124 124 112 127]\n",
            " [135 133 133 129 121 125 124 123 127 124]\n",
            " [137 136 135 137 137 136 134 139 132 125]\n",
            " [135 132 126 122 117 116 121 122 128 121]\n",
            " [132 126 129 135 132 131 130 130 130 127]\n",
            " [137 137 134 125 122 126 134 131 133 135]\n",
            " [137 139 138 130 138 139 138 134 136 135]\n",
            " [137 137 137 136 137 135 138 141 135 138]\n",
            " [139 138 136 136 136 141 134 136 137 138]\n",
            " [138 144 136 140 132 137 137 138 138 142]]\n",
            "[[ 87  93 103 115 119 116 105  98  84  76]\n",
            " [ 93 110 119 131 138 136 125 109  94  80]\n",
            " [ 97 121 134 145 157 159 147 124 103  87]\n",
            " [108 130 149 167 183 185 170 141 112  93]\n",
            " [116 136 162 193 217 218 199 158 123  99]\n",
            " [120 145 182 226 252 253 229 177 136 107]\n",
            " [133 157 199 249 252 252 250 198 150 113]\n",
            " [131 164 210 252 252 252 252 211 159 123]\n",
            " [131 163 209 253 252 252 252 218 169 131]\n",
            " [122 156 201 254 252 252 251 217 168 128]]\n",
            "[[  1   3   5   6   9  13  12   9  10   9]\n",
            " [  1   3   5   9  12  20  19  15  18  12]\n",
            " [  3   4   7  10  18  29  29  27  26  16]\n",
            " [  4   5   8  11  22  37  51  46  35  18]\n",
            " [  5   8  10  16  25  45  93  84  40  22]\n",
            " [  5   8  11  20  36  71 215 153  52  29]\n",
            " [  6   8  15  23  40  81 251 250  80  43]\n",
            " [  7  10  15  24  37  71 242 252  96  53]\n",
            " [  7  10  11  21  32  66 190 251  84  59]\n",
            " [ 10  10  11  21  32  64 105 118  75  54]]\n",
            "[[159 152 148 148 236  81  63  30  38 139]\n",
            " [149 152 151 153 206  69 213  36 147 150]\n",
            " [149 147 150 150 242  45  57  32 121 157]\n",
            " [148 149 146 149 251  55  71  31 159 169]\n",
            " [152 149 156 153 253  60  65  33 159 169]\n",
            " [136 171 187 163 253  55  65  37 178 185]\n",
            " [141 143 156 151 253  57  59  70 158 178]\n",
            " [141 144 149 141  97 147  62  45 160 188]\n",
            " [144 127 150 149 169 171  55 133 158 211]\n",
            " [150 150 138 151 141 143 125 150 159 193]]\n",
            "[[131 139 142 143 144 144 114 178 172 170]\n",
            " [134 137 142 144 143 148 144 178 178 181]\n",
            " [138 140 142 142 139 138 104 113 114 109]\n",
            " [139 143 142 147 147 142 114 105 108 114]\n",
            " [142 143 143 145 146 147 150 151 149 149]\n",
            " [143 145 145 145 148 150 146 150 147 146]\n",
            " [146 145 145 143 139 150 152 151 152 149]\n",
            " [144 144 145 146 146 145 147 132 131 145]\n",
            " [141 143 145 147 140 143 149 145 139 138]\n",
            " [144 144 145 146 148 142 142 151 149 146]]\n",
            "[[137 139 138 141 144 145 146 145 145 144]\n",
            " [138 141 144 145 145 145 145 144 144 145]\n",
            " [135 137 142 143 145 144 143 143 141 138]\n",
            " [136 137 142 143 144 145 143 142 139 139]\n",
            " [142 145 145 145 146 145 144 144 143 142]\n",
            " [142 144 149 150 152 151 149 146 148 148]\n",
            " [142 146 146 148 147 149 147 147 151 150]\n",
            " [141 144 144 143 145 144 143 142 143 142]\n",
            " [141 142 144 144 143 145 143 142 143 141]\n",
            " [144 141 141 143 144 142 143 143 144 143]]\n",
            "[[109 111 113 115 112 108 102  99  74  76]\n",
            " [126 124 128 124 129 125 125 126 123 125]\n",
            " [131 131 135 132 132 131 134 132 132 130]\n",
            " [135 133 136 136 135 135 133 131 129 129]\n",
            " [140 138 138 135 134 134 134 136 135 133]\n",
            " [134 134 134 135 133 133 133 136 135 133]\n",
            " [132 132 133 133 131 133 133 133 133 133]\n",
            " [133 132 135 132 132 132 132 132 132 132]\n",
            " [131 132 133 132 131 131 131 133 133 131]\n",
            " [131 130 131 132 131 128 131 133 135 132]]\n",
            "[[ 67 116  46 211 164  71  65  30  65  66]\n",
            " [138 122 104  77  90 115  68  36  65  66]\n",
            " [118  71 107  92 117 164 123  68  66  70]\n",
            " [108  99 129 122 137  84 120  69  71  73]\n",
            " [ 50 104 123 111 243 241 110 108  73  75]\n",
            " [153  38 109 142 114 116 107 102  78  81]\n",
            " [157  28 106 124 209 115  66 140  69  78]\n",
            " [147  43  59  98  95 127 139  73 118  78]\n",
            " [152  46  43  90 122  57 168 105  70  81]\n",
            " [157  28  69 107  87  99 152 101  65  80]]\n",
            "[[120 125 128 127 125 130 131 132 133 135]\n",
            " [128 130 130 130 131 133 136 136 138 140]\n",
            " [133 135 133 132 132 137 137 137 138 139]\n",
            " [116 120 121 125 131 138 139 139 141 141]\n",
            " [113 113 113 124 131 137 137 138 140 139]\n",
            " [125 118 118 130 137 140 138 138 141 139]\n",
            " [125 123 123 136 142 145 148 149 148 145]\n",
            " [124 124 130 138 143 145 146 166 149 149]\n",
            " [125 129 136 142 144 145 146 146 148 146]\n",
            " [123 133 139 142 145 144 146 147 148 146]]\n",
            "[[ 46  46  46  46  46  47  46  46  46  47]\n",
            " [ 47  47  47  50  72  82  46  62  47  82]\n",
            " [ 48  49  51  51  72  76  50  61  46  72]\n",
            " [ 51  53  54  55  60  65  86 101  89  61]\n",
            " [ 57  61  63  63  64  64  68  72  68  61]\n",
            " [ 76  88  89  80  80  80  80  80  72  68]\n",
            " [102 125 135 128 133 133 132 114 102 237]\n",
            " [110 124 148 153 155 155 146 129 117 248]\n",
            " [103 116 148 159 158 156 150 127 123 248]\n",
            " [ 90  94 116 122 122 123 123 105 117 251]]\n",
            "[[45 45 45 48 73 65 46 50 27 52]\n",
            " [40 44 46 50 65 60 57 23 22 43]\n",
            " [48 49 51 52 66 58 50 45 47 46]\n",
            " [60 49 46 46 71 70 64 66 88 36]\n",
            " [39 46 48 51 69 61 50 56 63 44]\n",
            " [24 42 59 60 77 80 63 63 63 30]\n",
            " [31 98 40 80 74 68 52 51 53 26]\n",
            " [46 73 47 59 67 64 56 58 47 61]\n",
            " [84 39 59 87 80 79 59 50 36 50]\n",
            " [45 44 44 62 84 89 67 44 58 45]]\n",
            "[[  9  10  10  10  10  10  10  10  10  10]\n",
            " [  9   9   9   9   9   9   9   9   9   9]\n",
            " [  9  11   9   9   9  10   9   9   9   9]\n",
            " [ 14  21  10  19  12  20  10   9   9  10]\n",
            " [ 16  16  18  18  12 111  10   9   9  10]\n",
            " [ 39  67  43  18  19  24  26  17  22  15]\n",
            " [122 119 120 119 117 121 122 119 117 121]\n",
            " [ 53  51  55  66  94 107 118 120 120 122]\n",
            " [ 51  53  52  51  52  53  55  53  54  50]\n",
            " [ 45  50  46  45  47  50  50  51  51  50]]\n",
            "[[  9   9   9   9   9   9   9   9   9   9]\n",
            " [  9   9   9   9   9   9   9   9   9   9]\n",
            " [  9   9   9   9   9  10   9   9   9   9]\n",
            " [  9  23  10  12  10  20 126  10   9   9]\n",
            " [ 16  18  20  22  85 190 140  16   9   9]\n",
            " [ 93  97  31 199 157 188 183   7   9  11]\n",
            " [120 118 206 197 186 187 186   1   1   2]\n",
            " [ 49 208 200 194 187 188 182   0   0   0]\n",
            " [179 206 200 194 187 188 180   0   0   0]\n",
            " [212 205 201 193 175 191 181   0   0   0]]\n",
            "[[ 9  9  9  9  9  8  9  9  9  9]\n",
            " [ 9  9  9  9  9  8  8  8  8  8]\n",
            " [ 9  9  9  9  9  8  8  8  8  9]\n",
            " [ 9  9  9  9  8  9  8  8  9  9]\n",
            " [10  9  9  9  8  8  9  8  8  9]\n",
            " [10  9  9  9 10  9  9  8  8  9]\n",
            " [12  9  9 11 16  9  8  9  9  8]\n",
            " [12  9  9 10 16  9  9  9 10 10]\n",
            " [13 11 10  9 12  9 10  9 10  9]\n",
            " [13 13 11 10 13 11 12 10 10 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcCLumE7NOSA",
        "colab_type": "code",
        "outputId": "9efe54b5-9595-4a60-a242-055d05068d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.shape(all_pictures)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 10, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZpSapuVUjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=all_pictures\n",
        "y=all_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfoFh3XuRG5e",
        "colab_type": "code",
        "outputId": "bef24321-73b3-47a0-a22e-a80c5fbc0a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "y=all_labels\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "y=encoder.fit_transform(y)\n",
        "enc=OneHotEncoder()\n",
        "y=np.reshape(y,(-1,1))\n",
        "y = pd.DataFrame(enc.fit_transform(y).toarray(),index=None)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1\n",
              "0   1.0  0.0\n",
              "1   1.0  0.0\n",
              "2   1.0  0.0\n",
              "3   1.0  0.0\n",
              "4   1.0  0.0\n",
              "5   1.0  0.0\n",
              "6   1.0  0.0\n",
              "7   1.0  0.0\n",
              "8   1.0  0.0\n",
              "9   1.0  0.0\n",
              "10  1.0  0.0\n",
              "11  1.0  0.0\n",
              "12  1.0  0.0\n",
              "13  1.0  0.0\n",
              "14  1.0  0.0\n",
              "15  1.0  0.0\n",
              "16  1.0  0.0\n",
              "17  1.0  0.0\n",
              "18  1.0  0.0\n",
              "19  1.0  0.0\n",
              "20  1.0  0.0\n",
              "21  1.0  0.0\n",
              "22  1.0  0.0\n",
              "23  1.0  0.0\n",
              "24  1.0  0.0\n",
              "25  0.0  1.0\n",
              "26  0.0  1.0\n",
              "27  0.0  1.0\n",
              "28  0.0  1.0\n",
              "29  0.0  1.0\n",
              "30  0.0  1.0\n",
              "31  0.0  1.0\n",
              "32  0.0  1.0\n",
              "33  0.0  1.0\n",
              "34  0.0  1.0\n",
              "35  0.0  1.0\n",
              "36  0.0  1.0\n",
              "37  0.0  1.0\n",
              "38  0.0  1.0\n",
              "39  0.0  1.0\n",
              "40  0.0  1.0\n",
              "41  0.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKVCvF3X6oqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=all_labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "y=encoder.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di3m-Irm5oDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y=np_utils.to_categorical(y, num_classes=len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NksjIFrxTCTH",
        "colab_type": "code",
        "outputId": "d3e7c621-6043-4f31-c571-d53027a207cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.shape(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24rSGvQdYjdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSbcnsxLu02S",
        "colab_type": "code",
        "outputId": "659f794a-6ef0-4480-ad03-0daaab4219cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x=np.array(x)\n",
        "x\n",
        "y=np.array(y)\n",
        "y\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33, 10, 10)\n",
            "(9, 10, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l-7KdtKO0R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train.reshape(33,10,10,1)\n",
        "x_test=x_test.reshape(9,10,10,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WWiVqTO8YJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "951W6edV8LS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(10,10,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbbuB64u8fOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1bzQXB-8pml",
        "colab_type": "code",
        "outputId": "4a68512a-05a0-4bc3-b659-88c4783f2181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test),batch_size=32)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33 samples, validate on 9 samples\n",
            "Epoch 1/100\n",
            "33/33 [==============================] - 0s 706us/step - loss: 0.2489 - accuracy: 0.9091 - val_loss: 0.8688 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 0s 567us/step - loss: 0.4704 - accuracy: 0.8788 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 0s 619us/step - loss: 0.2658 - accuracy: 0.9091 - val_loss: 0.7995 - val_accuracy: 0.6667\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 0s 557us/step - loss: 0.2718 - accuracy: 0.8788 - val_loss: 0.7827 - val_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 0s 551us/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.7870 - val_accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 0s 541us/step - loss: 0.2195 - accuracy: 0.9091 - val_loss: 0.8076 - val_accuracy: 0.6667\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 0s 567us/step - loss: 0.2303 - accuracy: 0.9091 - val_loss: 0.8447 - val_accuracy: 0.5556\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 0s 556us/step - loss: 0.2181 - accuracy: 0.9091 - val_loss: 0.9123 - val_accuracy: 0.5556\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 0s 499us/step - loss: 0.2239 - accuracy: 0.9091 - val_loss: 0.9906 - val_accuracy: 0.5556\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 0s 645us/step - loss: 0.2033 - accuracy: 0.9091 - val_loss: 1.0491 - val_accuracy: 0.5556\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 0s 575us/step - loss: 0.3932 - accuracy: 0.8788 - val_loss: 1.0403 - val_accuracy: 0.5556\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 0s 596us/step - loss: 0.2151 - accuracy: 0.8788 - val_loss: 1.0490 - val_accuracy: 0.5556\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 0s 564us/step - loss: 0.2277 - accuracy: 0.8485 - val_loss: 1.0569 - val_accuracy: 0.5556\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 0s 609us/step - loss: 0.2086 - accuracy: 0.8788 - val_loss: 1.0367 - val_accuracy: 0.5556\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 0s 578us/step - loss: 0.1644 - accuracy: 0.9697 - val_loss: 0.9964 - val_accuracy: 0.5556\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 0s 613us/step - loss: 0.1945 - accuracy: 0.9394 - val_loss: 0.9529 - val_accuracy: 0.5556\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 0s 579us/step - loss: 0.2125 - accuracy: 0.8485 - val_loss: 0.9104 - val_accuracy: 0.5556\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 0s 574us/step - loss: 0.2179 - accuracy: 0.8788 - val_loss: 0.8444 - val_accuracy: 0.5556\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 0s 612us/step - loss: 0.2194 - accuracy: 0.9091 - val_loss: 0.7784 - val_accuracy: 0.5556\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 0s 564us/step - loss: 0.2497 - accuracy: 0.8788 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 0s 570us/step - loss: 0.1836 - accuracy: 0.9091 - val_loss: 0.6329 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 0s 652us/step - loss: 0.2676 - accuracy: 0.8485 - val_loss: 0.6321 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 0s 645us/step - loss: 0.2267 - accuracy: 0.9091 - val_loss: 0.6671 - val_accuracy: 0.5556\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 0s 621us/step - loss: 0.2053 - accuracy: 0.9091 - val_loss: 0.7124 - val_accuracy: 0.5556\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 0s 608us/step - loss: 0.2006 - accuracy: 0.9091 - val_loss: 0.7548 - val_accuracy: 0.5556\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 0s 728us/step - loss: 0.2633 - accuracy: 0.8788 - val_loss: 0.7620 - val_accuracy: 0.5556\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 0s 679us/step - loss: 0.2311 - accuracy: 0.9091 - val_loss: 0.7975 - val_accuracy: 0.5556\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 0s 639us/step - loss: 0.2366 - accuracy: 0.8485 - val_loss: 0.8391 - val_accuracy: 0.5556\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 0s 680us/step - loss: 0.2339 - accuracy: 0.8788 - val_loss: 0.8685 - val_accuracy: 0.5556\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 0s 534us/step - loss: 0.1886 - accuracy: 0.9091 - val_loss: 0.8908 - val_accuracy: 0.5556\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 0s 599us/step - loss: 0.2110 - accuracy: 0.8485 - val_loss: 0.9083 - val_accuracy: 0.5556\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 0s 548us/step - loss: 0.1788 - accuracy: 0.9394 - val_loss: 0.9204 - val_accuracy: 0.5556\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 0s 611us/step - loss: 0.2003 - accuracy: 0.9091 - val_loss: 0.9537 - val_accuracy: 0.5556\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 0s 656us/step - loss: 0.1801 - accuracy: 0.9091 - val_loss: 0.9968 - val_accuracy: 0.5556\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 0s 624us/step - loss: 0.2696 - accuracy: 0.8485 - val_loss: 1.0751 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 0s 647us/step - loss: 0.1638 - accuracy: 0.9394 - val_loss: 1.1426 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 0s 604us/step - loss: 0.1955 - accuracy: 0.8788 - val_loss: 1.1783 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 0s 634us/step - loss: 0.1990 - accuracy: 0.9394 - val_loss: 1.1886 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 0s 601us/step - loss: 0.1749 - accuracy: 0.9091 - val_loss: 1.1993 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 0s 807us/step - loss: 0.1976 - accuracy: 0.9091 - val_loss: 1.2073 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 0s 643us/step - loss: 0.1911 - accuracy: 0.9091 - val_loss: 1.2141 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 0s 614us/step - loss: 0.1702 - accuracy: 0.9394 - val_loss: 1.2249 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 0s 625us/step - loss: 0.2176 - accuracy: 0.8788 - val_loss: 1.2356 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 0s 540us/step - loss: 0.1662 - accuracy: 0.9394 - val_loss: 1.2448 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 0s 629us/step - loss: 0.1873 - accuracy: 0.9394 - val_loss: 1.2533 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 0s 625us/step - loss: 0.2115 - accuracy: 0.9091 - val_loss: 1.2763 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 0s 639us/step - loss: 0.1485 - accuracy: 0.9394 - val_loss: 1.3007 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 0s 637us/step - loss: 0.1503 - accuracy: 0.9394 - val_loss: 1.3225 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 0s 645us/step - loss: 0.1516 - accuracy: 0.9091 - val_loss: 1.3383 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 0s 625us/step - loss: 0.1558 - accuracy: 0.9394 - val_loss: 1.3787 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 0s 594us/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 1.3251 - val_accuracy: 0.7778\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 0s 620us/step - loss: 0.2764 - accuracy: 0.9394 - val_loss: 1.4864 - val_accuracy: 0.5556\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 0s 586us/step - loss: 0.3589 - accuracy: 0.8788 - val_loss: 1.6100 - val_accuracy: 0.5556\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 0s 663us/step - loss: 0.3390 - accuracy: 0.9091 - val_loss: 1.7019 - val_accuracy: 0.5556\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 0s 684us/step - loss: 0.2336 - accuracy: 0.9091 - val_loss: 1.8116 - val_accuracy: 0.5556\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 0s 558us/step - loss: 0.2447 - accuracy: 0.9697 - val_loss: 2.0039 - val_accuracy: 0.4444\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 0s 614us/step - loss: 0.2516 - accuracy: 0.8485 - val_loss: 2.0898 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 0s 606us/step - loss: 0.1334 - accuracy: 0.9394 - val_loss: 2.0047 - val_accuracy: 0.7778\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 0s 571us/step - loss: 0.0795 - accuracy: 0.9697 - val_loss: 1.8208 - val_accuracy: 0.7778\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 0s 591us/step - loss: 0.2926 - accuracy: 0.9394 - val_loss: 1.6092 - val_accuracy: 0.7778\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 0s 621us/step - loss: 0.1943 - accuracy: 0.9091 - val_loss: 2.1757 - val_accuracy: 0.7778\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 0s 602us/step - loss: 0.6885 - accuracy: 0.9394 - val_loss: 2.1706 - val_accuracy: 0.7778\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 0s 606us/step - loss: 0.2216 - accuracy: 0.9394 - val_loss: 1.6862 - val_accuracy: 0.7778\n",
            "Epoch 64/100\n",
            "33/33 [==============================] - 0s 637us/step - loss: 0.3281 - accuracy: 0.9091 - val_loss: 1.0751 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "33/33 [==============================] - 0s 639us/step - loss: 0.1419 - accuracy: 0.9697 - val_loss: 0.8074 - val_accuracy: 0.5556\n",
            "Epoch 66/100\n",
            "33/33 [==============================] - 0s 691us/step - loss: 0.3024 - accuracy: 0.8788 - val_loss: 0.7103 - val_accuracy: 0.5556\n",
            "Epoch 67/100\n",
            "33/33 [==============================] - 0s 653us/step - loss: 0.4587 - accuracy: 0.8485 - val_loss: 0.7274 - val_accuracy: 0.5556\n",
            "Epoch 68/100\n",
            "33/33 [==============================] - 0s 682us/step - loss: 0.2731 - accuracy: 0.9091 - val_loss: 0.8322 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "33/33 [==============================] - 0s 689us/step - loss: 0.4417 - accuracy: 0.8485 - val_loss: 1.0789 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "33/33 [==============================] - 0s 632us/step - loss: 0.1152 - accuracy: 0.9394 - val_loss: 1.2200 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "33/33 [==============================] - 0s 631us/step - loss: 0.1225 - accuracy: 0.9091 - val_loss: 1.4526 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "33/33 [==============================] - 0s 597us/step - loss: 0.1638 - accuracy: 0.9394 - val_loss: 1.6270 - val_accuracy: 0.7778\n",
            "Epoch 73/100\n",
            "33/33 [==============================] - 0s 614us/step - loss: 0.2158 - accuracy: 0.9091 - val_loss: 1.7501 - val_accuracy: 0.7778\n",
            "Epoch 74/100\n",
            "33/33 [==============================] - 0s 725us/step - loss: 0.2412 - accuracy: 0.8788 - val_loss: 1.8072 - val_accuracy: 0.7778\n",
            "Epoch 75/100\n",
            "33/33 [==============================] - 0s 587us/step - loss: 0.2879 - accuracy: 0.8788 - val_loss: 1.8042 - val_accuracy: 0.7778\n",
            "Epoch 76/100\n",
            "33/33 [==============================] - 0s 706us/step - loss: 0.4144 - accuracy: 0.8182 - val_loss: 1.7284 - val_accuracy: 0.7778\n",
            "Epoch 77/100\n",
            "33/33 [==============================] - 0s 642us/step - loss: 0.2411 - accuracy: 0.9091 - val_loss: 1.6671 - val_accuracy: 0.7778\n",
            "Epoch 78/100\n",
            "33/33 [==============================] - 0s 501us/step - loss: 0.2487 - accuracy: 0.8788 - val_loss: 1.5730 - val_accuracy: 0.7778\n",
            "Epoch 79/100\n",
            "33/33 [==============================] - 0s 750us/step - loss: 0.2672 - accuracy: 0.8788 - val_loss: 1.4040 - val_accuracy: 0.7778\n",
            "Epoch 80/100\n",
            "33/33 [==============================] - 0s 575us/step - loss: 0.2488 - accuracy: 0.8788 - val_loss: 1.2183 - val_accuracy: 0.7778\n",
            "Epoch 81/100\n",
            "33/33 [==============================] - 0s 622us/step - loss: 0.2035 - accuracy: 0.8788 - val_loss: 1.0605 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "33/33 [==============================] - 0s 588us/step - loss: 0.3282 - accuracy: 0.8788 - val_loss: 0.8825 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "33/33 [==============================] - 0s 683us/step - loss: 0.1965 - accuracy: 0.9091 - val_loss: 0.7265 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "33/33 [==============================] - 0s 746us/step - loss: 0.1766 - accuracy: 0.8788 - val_loss: 0.6207 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "33/33 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.8485 - val_loss: 0.5733 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "33/33 [==============================] - 0s 696us/step - loss: 0.1916 - accuracy: 0.8788 - val_loss: 0.5516 - val_accuracy: 0.7778\n",
            "Epoch 87/100\n",
            "33/33 [==============================] - 0s 587us/step - loss: 0.2266 - accuracy: 0.8788 - val_loss: 0.5424 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "33/33 [==============================] - 0s 600us/step - loss: 0.2035 - accuracy: 0.9091 - val_loss: 0.5455 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 628us/step - loss: 0.1916 - accuracy: 0.9091 - val_loss: 0.5480 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "33/33 [==============================] - 0s 663us/step - loss: 0.2231 - accuracy: 0.9091 - val_loss: 0.4842 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "33/33 [==============================] - 0s 620us/step - loss: 0.2332 - accuracy: 0.8788 - val_loss: 0.4296 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "33/33 [==============================] - 0s 635us/step - loss: 0.2262 - accuracy: 0.8182 - val_loss: 0.3896 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "33/33 [==============================] - 0s 630us/step - loss: 0.2129 - accuracy: 0.9091 - val_loss: 0.3616 - val_accuracy: 0.8889\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 523us/step - loss: 0.2084 - accuracy: 0.8788 - val_loss: 0.3426 - val_accuracy: 0.7778\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 596us/step - loss: 0.2152 - accuracy: 0.8485 - val_loss: 0.3298 - val_accuracy: 0.7778\n",
            "Epoch 96/100\n",
            "33/33 [==============================] - 0s 593us/step - loss: 0.2118 - accuracy: 0.8788 - val_loss: 0.3191 - val_accuracy: 0.7778\n",
            "Epoch 97/100\n",
            "33/33 [==============================] - 0s 602us/step - loss: 0.2086 - accuracy: 0.8788 - val_loss: 0.3112 - val_accuracy: 0.7778\n",
            "Epoch 98/100\n",
            "33/33 [==============================] - 0s 649us/step - loss: 0.1796 - accuracy: 0.8788 - val_loss: 0.3056 - val_accuracy: 0.7778\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 697us/step - loss: 0.1464 - accuracy: 0.9091 - val_loss: 0.3028 - val_accuracy: 0.7778\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 643us/step - loss: 0.1880 - accuracy: 0.9091 - val_loss: 0.3020 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f66ff868a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fSeUFLF87_5",
        "colab_type": "code",
        "outputId": "f1ff3a4a-646b-444d-ee87-74494fccaf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "\n",
        "prediction = model.predict_classes(x_test)\n",
        "print(prediction)\n",
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok4ETWXHYkcV",
        "colab_type": "code",
        "outputId": "3793bb3e-ce3e-4ab5-e2cb-c68348ce7f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9a4d3f83fefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv5ew2G6O63G",
        "colab_type": "code",
        "outputId": "176cd7b7-42c0-479f-8a0e-d4840dbf2e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 3.3610876e-16],\n",
              "       [1.0000000e+00, 5.6974930e-08],\n",
              "       [1.0000000e+00, 1.9736567e-11],\n",
              "       [1.0000000e+00, 2.7482162e-15],\n",
              "       [1.0000000e+00, 7.1345486e-18],\n",
              "       [1.0000000e+00, 7.4767547e-15]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL3NfPgRlbHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in images:\n",
        "    image=cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
        "    image=cv2.resize(image,dim)\n",
        "    allpictures.append(np.array(img))\n",
        "    alllabels.append(label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pl0M1xPh2lO",
        "colab_type": "code",
        "outputId": "f36cb4c1-b83b-4383-a274-1079cf887c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['frame315720.jpg',\n",
              " 'frame312480.jpg',\n",
              " 'frame310320.jpg',\n",
              " 'frame308880.jpg',\n",
              " 'frame306720.jpg',\n",
              " 'frame303840.jpg',\n",
              " 'frame362880.jpg',\n",
              " 'frame335160.jpg',\n",
              " 'frame302760.jpg',\n",
              " 'frame297720.jpg',\n",
              " 'frame297360.jpg',\n",
              " 'frame297000.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}